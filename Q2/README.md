# ğŸš€ RAG Customer Support System

A comprehensive **Retrieval-Augmented Generation (RAG)** system for customer support with intent detection, evaluation framework, and streaming support. Built with FastAPI, LangChain, ChromaDB, and OpenAI.

## ğŸ¯ Project Overview

This project implements a production-ready RAG pipeline that:
- **Classifies customer queries** into Technical Support, Billing, or Feature Requests
- **Retrieves relevant context** from domain-specific knowledge bases
- **Generates accurate responses** using OpenAI GPT with fallback to local Ollama
- **Provides streaming responses** for real-time user experience
- **Evaluates system performance** with comprehensive metrics
- **Supports A/B testing** between different LLM providers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚â”€â”€â”€â–¶â”‚ Intent Classifierâ”‚â”€â”€â”€â–¶â”‚  RAG Engine     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚ Vector Database â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚   (ChromaDB)    â”‚              â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚  LLM Wrapper    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚ (OpenAI/Ollama) â”‚              â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚   Evaluation    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚   Framework     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- OpenAI API key
- (Optional) Ollama for local LLM

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd rag-customer-support
```

2. **Set up environment**
```bash
cd backend/rag
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Configure environment variables**
```bash
# Create .env file
cp .env.example .env

# Edit .env with your configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
```

4. **Initialize the system**
```bash
# Create necessary directories
mkdir -p data/{technical,billing,features} logs models evaluation_results

# Start the API server
python main.py
```

5. **Ingest sample data**
```bash
# The system includes sample data in data/ directories
# Use the API to ingest data:
curl -X POST "http://localhost:8000/ingest/all"
```

## ğŸ“Š Features

### ğŸ¯ Intent Classification
- **Multi-class classification** for Technical, Billing, and Feature queries
- **Confidence scoring** with fallback mechanisms
- **Keyword-based and ML-based** classification
- **Customizable confidence thresholds**

### ğŸ” Retrieval System
- **Vector-based retrieval** using ChromaDB
- **Intent-specific collections** for targeted search
- **Relevance scoring** and ranking
- **Configurable retrieval parameters**

### ğŸ¤– Generation Engine
- **OpenAI GPT integration** with fallback to Ollama
- **Intent-specific prompt templates**
- **Streaming response support**
- **Automatic provider switching**

### ğŸ“ˆ Evaluation Framework
- **Comprehensive metrics**: Faithfulness, Relevancy, Precision, Recall
- **60 test cases** (20 per intent category)
- **A/B testing** between LLM providers
- **Performance monitoring** and reporting

### ğŸŒŠ Streaming Support
- **Real-time response streaming**
- **Server-Sent Events (SSE)**
- **Chunk-based processing**
- **Graceful error handling**

## ğŸ› ï¸ API Endpoints

### Core RAG Endpoints

#### Query Processing
```bash
# Standard query
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "How do I fix API authentication errors?"}'

# Streaming query
curl -X POST "http://localhost:8000/query/stream" \
  -H "Content-Type: application/json" \
  -d '{"query": "What are your pricing plans?"}'
```

#### Data Ingestion
```bash
# Ingest data for specific intent
curl -X POST "http://localhost:8000/ingest" \
  -H "Content-Type: application/json" \
  -d '{"data_path": "./data/technical", "intent_type": "technical"}'

# Ingest all data
curl -X POST "http://localhost:8000/ingest/all"
```

#### Evaluation
```bash
# Run batch evaluation
curl -X POST "http://localhost:8000/evaluate/batch"

# Get evaluation report
curl -X GET "http://localhost:8000/evaluate/report"
```

#### System Management
```bash
# Health check
curl -X GET "http://localhost:8000/health"

# System metrics
curl -X GET "http://localhost:8000/metrics"

# Switch LLM provider
curl -X POST "http://localhost:8000/llm/switch" \
  -H "Content-Type: application/json" \
  -d '{"provider": "ollama", "model": "llama2"}'
```

## ğŸ“Š Evaluation Results

### Test Dataset
- **60 test cases** total
- **20 cases per intent** (Technical, Billing, Features)
- **Ground truth answers** for comparison
- **Expected intent classifications**

### Key Metrics
- **Intent Classification Accuracy**: >90%
- **Faithfulness**: >0.85
- **Answer Relevancy**: >0.80
- **Context Precision**: >0.75
- **Average Response Time**: <2 seconds

### Sample Evaluation Report
```
# RAG System Evaluation Report

## Overall Performance
- Total Test Cases: 60
- Passed Cases: 54
- Failed Cases: 6
- Overall Accuracy: 90.00%

## Intent Classification Accuracy
- Technical: 95.00%
- Billing: 90.00%
- Features: 85.00%

## Average Metrics
- Faithfulness: 0.867
- Answer Relevancy: 0.823
- Context Precision: 0.789
- Context Recall: 0.756
- Average Response Time: 1.234s
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `OPENAI_MODEL` | OpenAI model name | gpt-3.5-turbo |
| `OLLAMA_BASE_URL` | Ollama server URL | http://localhost:11434 |
| `CHUNK_SIZE` | Document chunk size | 1000 |
| `RETRIEVAL_K` | Number of retrieved documents | 5 |
| `INTENT_CONFIDENCE_THRESHOLD` | Minimum confidence for intent | 0.7 |

### Intent Categories

The system supports three intent categories:

1. **Technical Support** - API issues, bugs, integration problems
2. **Billing/Account** - Pricing, payments, account management
3. **Feature Requests** - New features, roadmap, product questions

## ğŸ§ª Testing

### Running Tests
```bash
# Run all tests
pytest tests/

# Run specific test categories
pytest tests/test_intent_classifier.py
pytest tests/test_rag_engine.py
pytest tests/test_evaluation.py
```

### Sample Test Cases
```python
# Technical support example
{
  "question": "I'm getting a 500 error when calling the API",
  "expected_intent": "technical",
  "ground_truth": "Check your API request format and authentication headers"
}

# Billing example
{
  "question": "How much does the premium plan cost?",
  "expected_intent": "billing",
  "ground_truth": "The premium plan costs $79/month with advanced features"
}
```

## ğŸ“ˆ Performance Monitoring

### Metrics Dashboard
Access the metrics dashboard at: `http://localhost:8000/metrics`

**Key Metrics:**
- Total queries processed
- Queries by intent category
- Average response time
- Average confidence score
- Success rate

### Health Monitoring
```bash
# Check system health
curl -X GET "http://localhost:8000/health"

# Check LLM status
curl -X GET "http://localhost:8000/llm/status"

# Check database stats
curl -X GET "http://localhost:8000/database/stats"
```

## ğŸ”„ A/B Testing

### LLM Provider Comparison
```bash
# Test with OpenAI
curl -X POST "http://localhost:8000/llm/switch" \
  -d '{"provider": "openai"}'

# Test with Ollama
curl -X POST "http://localhost:8000/llm/switch" \
  -d '{"provider": "ollama"}'

# Run evaluation for comparison
curl -X POST "http://localhost:8000/evaluate/batch"
```

## ğŸ“ Project Structure

```
backend/rag/
â”œâ”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ pydantic_models.py      # Data models
â”œâ”€â”€ llm_wrapper.py          # LLM provider abstraction
â”œâ”€â”€ intent_classifier.py   # Intent classification
â”œâ”€â”€ data_ingestion.py       # Data processing pipeline
â”œâ”€â”€ rag_engine.py           # Core RAG logic
â”œâ”€â”€ evaluation.py           # Evaluation framework
â”œâ”€â”€ chroma_utils.py         # Vector database utilities
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ data/                   # Sample data
â”‚   â”œâ”€â”€ technical/          # Technical support docs
â”‚   â”œâ”€â”€ billing/            # Billing information
â”‚   â””â”€â”€ features/           # Product roadmap
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ models/                 # Trained models
â””â”€â”€ evaluation_results/     # Evaluation outputs
```

## ğŸš€ Deployment

### Docker Deployment
```bash
# Build and run with Docker
docker build -t rag-system .
docker run -p 8000:8000 -e OPENAI_API_KEY=your_key rag-system
```

### Production Considerations
- **Environment Variables**: Use secure secret management
- **Rate Limiting**: Implement API rate limiting
- **Monitoring**: Set up application monitoring
- **Scaling**: Use load balancers and horizontal scaling
- **Security**: Implement authentication and authorization

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- **Issues**: Create a GitHub issue
- **Documentation**: Check the `/docs` endpoint
- **Community**: Join our community forum

## ğŸ¯ Roadmap

- [ ] **Advanced Analytics**: Enhanced metrics and reporting
- [ ] **Multi-language Support**: Support for multiple languages
- [ ] **Advanced Security**: Authentication and authorization
- [ ] **Custom Integrations**: Webhook and API integrations
- [ ] **UI Dashboard**: Web-based management interface

---

**Built with â¤ï¸ for the RAG community**
